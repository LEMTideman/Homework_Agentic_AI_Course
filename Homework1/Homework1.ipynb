{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b4d729-3a7d-4179-8526-b1fb7d69125c",
   "metadata": {},
   "source": [
    "## Homework 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0abf2a66-2440-470e-a157-704c7663ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import tiktoken\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "from markitdown import MarkItDown\n",
    "from gitsource import chunk_documents\n",
    "from typing import List, Dict, Any, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from minsearch import Index\n",
    "\n",
    "CSV_FILE = Path(\"books.csv\")\n",
    "PDF_DIR = Path(\"downloads\")\n",
    "MARKDOWN_DIR = Path(\"books_text\")\n",
    "URL_COLUMN = \"pdf_url\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5acfca11-44c5-43c4-9f52-6eadc195f10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuro-symbolic AI is an approach that combines neural networks with symbolic reasoning to leverage the strengths of both paradigms. This integration allows for the learning capabilities of neural networks to be enhanced by the structured logic and interpretability of symbolic systems. As a result, neuro-symbolic AI aims to create more robust and explainable artificial intelligence solutions, capable of reasoning about complex data while still learning from it.\n"
     ]
    }
   ],
   "source": [
    "# Test LLM call\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_client = OpenAI()\n",
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"What is neuro-symbolic AI? Give me a three sentence definition.\"\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40a94c-a641-4da1-bdcf-4b53ebf1bcff",
   "metadata": {},
   "source": [
    "#### Download the books listed in books.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653983f4-5a13-406b-b18c-410a18d4f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Downloaded: thinkpython2.pdf\n",
      "✅ Downloaded: thinkdsp.pdf\n",
      "✅ Downloaded: thinkcomplexity2.pdf\n",
      "✅ Downloaded: thinkjava2.pdf\n",
      "✅ Downloaded: PhysicalModelingInMatlab4.pdf\n",
      "✅ Downloaded: thinkos.pdf\n",
      "✅ Downloaded: Think-C.pdf\n"
     ]
    }
   ],
   "source": [
    "# Create directory\n",
    "PDF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def filename_from_url(url: str) -> str:\n",
    "    path = urlparse(url).path\n",
    "    name = Path(path).name\n",
    "    return name if name else \"downloaded_file.pdf\"\n",
    "\n",
    "with CSV_FILE.open(newline=\"\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        url = row[URL_COLUMN]\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, stream=True, timeout=30)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            filename = filename_from_url(url)\n",
    "            filepath = PDF_DIR / filename   # ✅ Path join\n",
    "\n",
    "            with filepath.open(\"wb\") as out:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    out.write(chunk)\n",
    "\n",
    "            print(f\"✅ Downloaded: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to download {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63133f0b-9f4a-45bb-aa49-bc8e58cd3995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fae9f606-1b10-4186-8f0c-ea147438176c",
   "metadata": {},
   "source": [
    "#### PDF to Markdown Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7822bc08-2a79-4566-a524-7ec0d5e6ac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted: PhysicalModelingInMatlab4.pdf → PhysicalModelingInMatlab4.md\n",
      "✅ Converted: Think-C.pdf → Think-C.md\n",
      "✅ Converted: thinkcomplexity2.pdf → thinkcomplexity2.md\n",
      "✅ Converted: thinkdsp.pdf → thinkdsp.md\n",
      "✅ Converted: thinkjava2.pdf → thinkjava2.md\n",
      "✅ Converted: thinkos.pdf → thinkos.md\n",
      "✅ Converted: thinkpython2.pdf → thinkpython2.md\n"
     ]
    }
   ],
   "source": [
    "# Create directory\n",
    "MARKDOWN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "md = MarkItDown()\n",
    "\n",
    "pdf_files = list(PDF_DIR.glob(\"*.pdf\"))\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"No PDF files found.\")\n",
    "    exit(0)\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    try:\n",
    "        result = md.convert(pdf_path)\n",
    "\n",
    "        output_file = MARKDOWN_DIR / f\"{pdf_path.stem}.md\"\n",
    "        output_file.write_text(result.text_content, encoding=\"utf-8\")\n",
    "\n",
    "        print(f\"✅ Converted: {pdf_path.name} → {output_file.name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to convert {pdf_path.name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ecce4-4a14-4127-b84e-ed4a19a2c49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1add513-7f22-4cd6-b1a2-ce3a3b6cb9c5",
   "metadata": {},
   "source": [
    "#### Chunking for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94e418a6-a5ae-454a-8065-8a83f9f2904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_book_as_line_doc(md_path: Path) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Input: one markdown file\n",
    "    Output:\n",
    "      {\n",
    "        \"source\": \"<filename.md>\",\n",
    "        \"content\": [<non-empty line>, ...]\n",
    "      }\n",
    "    \"\"\"\n",
    "    text = md_path.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "\n",
    "    lines = [line.strip() for line in text.splitlines()]\n",
    "    lines = [line for line in lines if line]\n",
    "\n",
    "    return {\n",
    "        \"source\": md_path.name,\n",
    "        \"content\": lines,\n",
    "    }\n",
    "\n",
    "def to_gitsource_document(line_doc: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Converts:\n",
    "      {\n",
    "        \"source\": \"...\",\n",
    "        \"content\": [lines]\n",
    "      }\n",
    "    → {\n",
    "        \"filename\": \"...\",\n",
    "        \"content\": [lines]\n",
    "      }\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"filename\": line_doc[\"source\"],\n",
    "        \"content\": line_doc[\"content\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae3e7bc-5e56-40f7-8a59-52bf243734b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PhysicalModelingInMatlab4.md: 106 chunks\n",
      "✅ Think-C.md: 109 chunks\n",
      "✅ thinkcomplexity2.md: 130 chunks\n",
      "✅ thinkdsp.md: 86 chunks\n",
      "✅ thinkjava2.md: 216 chunks\n",
      "✅ thinkos.md: 62 chunks\n",
      "✅ thinkpython2.md: 214 chunks\n",
      "\n",
      "Total chunks created: 923\n"
     ]
    }
   ],
   "source": [
    "all_chunks = []\n",
    "\n",
    "for md_path in sorted(MARKDOWN_DIR.glob(\"*.md\")):\n",
    "    # Load one book\n",
    "    line_doc = load_book_as_line_doc(md_path)\n",
    "\n",
    "    # Convert to gitsource format\n",
    "    gs_doc = to_gitsource_document(line_doc)\n",
    "\n",
    "    # Item-based chunking of the book (one item = one line)\n",
    "    # Slidding window with 100 items per chunk, step size of 50\n",
    "    chunks = chunk_documents(documents=[to_gitsource_document(line_doc)],\n",
    "                             size=100, step=50)\n",
    "\n",
    "    # Append chunks\n",
    "    all_chunks.extend(chunks)\n",
    "    print(f\"✅ {md_path.name}: {len(chunks)} chunks\")\n",
    "\n",
    "print(f\"\\nTotal chunks created: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17753d1e-1fb9-4bf9-a6b0-7889fd437367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9202c54a-c827-4a63-8fc8-79f249cec2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinkpython2.md 214 chunks\n"
     ]
    }
   ],
   "source": [
    "# Number of chunks in Think Python 2\n",
    "count = sum(\n",
    "    1 for c in all_chunks\n",
    "    if c.get(\"filename\") == \"thinkpython2.md\"\n",
    ")\n",
    "print(\"thinkpython2.md\", count, \"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caec900-3c60-4df1-9ecc-1dca1c5f52f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f0840c4-b2fd-4fc4-bb83-f7a3848baabe",
   "metadata": {},
   "source": [
    "#### Indexing with minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9399ebc-6862-4d21-96a0-21465e58c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_documents_for_search(all_chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Converts gitsource chunks into documents suitable for minsearch.Index.fit()\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "\n",
    "    for i, chunk in enumerate(all_chunks):\n",
    "        # chunk[\"content\"] is a LIST (item-based chunking)\n",
    "        text = \"\\n\".join(chunk[\"content\"])\n",
    "\n",
    "        doc = {\n",
    "            \"id\": f\"{chunk.get('filename', 'doc')}_{i}\",\n",
    "            \"text\": text,\n",
    "            \"source\": chunk.get(\"filename\"),\n",
    "        }\n",
    "\n",
    "        documents.append(doc)\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8c1968-0804-47e5-9718-c811d69b16cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x1a55c750620>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert each chunk (list of lines) into an indexed block of text\n",
    "documents = prepare_documents_for_search(all_chunks)\n",
    "\n",
    "# Use indexing from the minsearch library\n",
    "index = Index(text_fields=[\"text\"])\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95834f1-b2ad-448c-b5cc-baecda1c9a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8f91e5c-5f03-4973-9ddb-63c1baa0c495",
   "metadata": {},
   "source": [
    "#### Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2de066b5-dd39-4fc8-bc7e-42705dae28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical (rather than semantic) search with the minsearch library\n",
    "results = index.search(\"python function definition\", num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b43974-a685-4cb2-919f-45703cddbdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thinkpython2.md'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minsearch returns results sorted by descending relevance\n",
    "# The most relevant match for the above user-query is:\n",
    "results[0]['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df82d14c-1d04-4756-a5cd-89f56dbf59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full RAG pipeline\n",
    "instructions = \"\"\"\n",
    "You're a course assistant, your task is to answer the QUESTION from the\n",
    "course students using the provided CONTEXT\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(question, search_results):\n",
    "    context = json.dumps(search_results, indent=2)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context\n",
    "    ).strip()\n",
    "    return prompt\n",
    "\n",
    "def search(question):\n",
    "    return index.search(question, num_results=5)\n",
    "\n",
    "def llm(user_prompt, instructions, model='gpt-4o-mini'):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instructions},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        model=model,\n",
    "        input=messages\n",
    "    )\n",
    "\n",
    "    return response.output_text\n",
    "\n",
    "def count_input_tokens(instructions, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "\n",
    "    system_tokens = len(encoding.encode(instructions))\n",
    "    user_tokens = len(encoding.encode(user_prompt))\n",
    "\n",
    "    return {\n",
    "        \"system_tokens\": system_tokens,\n",
    "        \"user_tokens\": user_tokens,\n",
    "        \"total_input_tokens\": system_tokens + user_tokens,\n",
    "    }\n",
    "\n",
    "def rag(query):\n",
    "    # Define prompt, including lexical search results\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "\n",
    "    # Count the number of input tokens for one RAG query\n",
    "    token_stats = count_input_tokens(instructions, prompt)\n",
    "    print(token_stats)\n",
    "\n",
    "    # Return LLM output\n",
    "    answer = llm(prompt, instructions)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c314cdd-b2bf-4b9d-8fc2-5ed6cd085e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system_tokens': 24, 'user_tokens': 6926, 'total_input_tokens': 6950}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A Python function is defined using the `def` keyword, followed by the function name and parentheses that may contain parameters. The function\\'s body, which contains the statements that perform the operation, is indented beneath the definition line. \\n\\nHere\\'s a basic structure for a function definition:\\n\\n```python\\ndef function_name(parameters):\\n    # body of the function\\n    statement(s)\\n    return value  # optional\\n```\\n\\n### Example:\\nHere\\'s a simple function that takes a parameter and prints a message:\\n\\n```python\\ndef greet(name):\\n    print(\"Hello, \" + name + \"!\")\\n```\\n\\nYou can call this function with an argument:\\n\\n```python\\ngreet(\\'Alice\\')\\n```\\n\\nThis would output:\\n```\\nHello, Alice!\\n```\\n\\nFunctions may return values using the `return` statement, allowing for value processing and manipulation. Functions can also take multiple parameters and perform various operations based on the logic defined within the body.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"python function definition\"\n",
    "rag(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2917a8c-e434-464a-8f6b-c6822f0fc261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f2c4309-8817-4813-93e3-fae913457418",
   "metadata": {},
   "source": [
    "#### RAG with Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7245e45-eecd-44b2-8bc2-4f8a444807ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGResponse(BaseModel):\n",
    "    answer: str = Field(description=\"The main answer to the user's question in markdown\")\n",
    "    found_answer: bool = Field(description=\"True if relevant information was found in the documentation\")\n",
    "    confidence: float = Field(description=\"Confidence score from 0.0 to 1.0\")\n",
    "    confidence_explanation: str = Field(description=\"Explanation about the confidence level\")\n",
    "    answer_type: Literal[\"how-to\", \"explanation\", \"troubleshooting\", \"comparison\", \"reference\"] = Field(description=\"The category of the answer\")\n",
    "    followup_questions: list[str] = Field(description=\"Suggested follow-up questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa8ad261-8d73-4eb1-a1cd-92aceb327fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(user_prompt, instructions, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instructions},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"user\", \"content\": (\n",
    "            \"Respond ONLY as valid JSON matching this schema:\\n\"\n",
    "            f\"{RAGResponse.model_json_schema()}\\n\"\n",
    "            \"Do not include any extra keys. Do not wrap in markdown.\"\n",
    "        )},\n",
    "    ]\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        model=model,\n",
    "        input=messages,\n",
    "        # This nudges the API to return JSON (if supported in your client/version)\n",
    "        text={\"format\": {\"type\": \"json_object\"}},\n",
    "    )\n",
    "\n",
    "    # Parse JSON text into Pydantic model\n",
    "    data = json.loads(response.output_text)\n",
    "    return RAGResponse.model_validate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe98c08a-71ad-451b-b647-1a4f8b834772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "\n",
    "    token_stats = count_input_tokens(instructions, prompt)\n",
    "    print(token_stats)\n",
    "\n",
    "    structured = llm(prompt, instructions)  # now returns RAGResponse\n",
    "    return structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d4af325-7f80-4a95-a73d-285a421d22e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system_tokens': 24, 'user_tokens': 6926, 'total_input_tokens': 6950}\n",
      "answer='In Python, a function is defined using the `def` keyword, followed by the function name and parentheses containing any parameters. The function body is indented and contains the statements that will be executed when the function is called. Here is an example:\\n\\n```python\\ndef my_function(parameter1, parameter2):\\n    # Function body\\n    return parameter1 + parameter2\\n```\\n\\nThe above function takes two parameters and returns their sum.' found_answer=True confidence=0.9 confidence_explanation='The explanation includes a clear and concise definition of a function, along with an example, which reflects common practices in Python programming.' answer_type='how-to' followup_questions=['Can you explain the difference between a function and a method in Python?', 'What are parameters and arguments in Python functions?', 'How can I return multiple values from a function in Python?']\n",
      "In Python, a function is defined using the `def` keyword, followed by the function name and parentheses containing any parameters. The function body is indented and contains the statements that will be executed when the function is called. Here is an example:\n",
      "\n",
      "```python\n",
      "def my_function(parameter1, parameter2):\n",
      "    # Function body\n",
      "    return parameter1 + parameter2\n",
      "```\n",
      "\n",
      "The above function takes two parameters and returns their sum.\n",
      "0.9\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "result = rag(\"python function definition\")\n",
    "\n",
    "print(result)                 # shows the full model\n",
    "print(result.answer)          # just the markdown answer\n",
    "print(result.confidence)      # confidence number\n",
    "print(result.found_answer)    # True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a6d6f-8852-4b29-81e2-a25daa8fd09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
