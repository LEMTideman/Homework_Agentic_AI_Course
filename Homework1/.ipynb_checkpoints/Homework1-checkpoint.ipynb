{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b4d729-3a7d-4179-8526-b1fb7d69125c",
   "metadata": {},
   "source": [
    "## Homework 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0abf2a66-2440-470e-a157-704c7663ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "from markitdown import MarkItDown\n",
    "from gitsource import chunk_documents\n",
    "from typing import List, Dict, Any\n",
    "from minsearch import Index\n",
    "\n",
    "CSV_FILE = Path(\"books.csv\")\n",
    "PDF_DIR = Path(\"downloads\")\n",
    "MARKDOWN_DIR = Path(\"books_text\")\n",
    "URL_COLUMN = \"pdf_url\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5acfca11-44c5-43c4-9f52-6eadc195f10b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test LLM call\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m openai_client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m response = openai_client.responses.create(\n\u001b[32m      5\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mWhat is AI?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.output_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Course_Alexey_Grigorev\\Homework_AI_Engineering\\.venv\\Lib\\site-packages\\openai\\_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    135\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Test LLM call\n",
    "from openai import OpenAI\n",
    "openai_client = OpenAI()\n",
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"What is AI?\"\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40a94c-a641-4da1-bdcf-4b53ebf1bcff",
   "metadata": {},
   "source": [
    "#### Download the books listed in books.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653983f4-5a13-406b-b18c-410a18d4f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Downloaded: thinkpython2.pdf\n",
      "✅ Downloaded: thinkdsp.pdf\n",
      "✅ Downloaded: thinkcomplexity2.pdf\n",
      "✅ Downloaded: thinkjava2.pdf\n",
      "✅ Downloaded: PhysicalModelingInMatlab4.pdf\n",
      "✅ Downloaded: thinkos.pdf\n",
      "✅ Downloaded: Think-C.pdf\n"
     ]
    }
   ],
   "source": [
    "# Create directory\n",
    "PDF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def filename_from_url(url: str) -> str:\n",
    "    path = urlparse(url).path\n",
    "    name = Path(path).name\n",
    "    return name if name else \"downloaded_file.pdf\"\n",
    "\n",
    "with CSV_FILE.open(newline=\"\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        url = row[URL_COLUMN]\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, stream=True, timeout=30)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            filename = filename_from_url(url)\n",
    "            filepath = PDF_DIR / filename   # ✅ Path join\n",
    "\n",
    "            with filepath.open(\"wb\") as out:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    out.write(chunk)\n",
    "\n",
    "            print(f\"✅ Downloaded: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to download {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63133f0b-9f4a-45bb-aa49-bc8e58cd3995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fae9f606-1b10-4186-8f0c-ea147438176c",
   "metadata": {},
   "source": [
    "#### PDF to Markdown Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7822bc08-2a79-4566-a524-7ec0d5e6ac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted: PhysicalModelingInMatlab4.pdf → PhysicalModelingInMatlab4.md\n",
      "✅ Converted: Think-C.pdf → Think-C.md\n",
      "✅ Converted: thinkcomplexity2.pdf → thinkcomplexity2.md\n",
      "✅ Converted: thinkdsp.pdf → thinkdsp.md\n",
      "✅ Converted: thinkjava2.pdf → thinkjava2.md\n",
      "✅ Converted: thinkos.pdf → thinkos.md\n",
      "✅ Converted: thinkpython2.pdf → thinkpython2.md\n"
     ]
    }
   ],
   "source": [
    "# Create directory\n",
    "MARKDOWN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "md = MarkItDown()\n",
    "\n",
    "pdf_files = list(PDF_DIR.glob(\"*.pdf\"))\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"No PDF files found.\")\n",
    "    exit(0)\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    try:\n",
    "        result = md.convert(pdf_path)\n",
    "\n",
    "        output_file = MARKDOWN_DIR / f\"{pdf_path.stem}.md\"\n",
    "        output_file.write_text(result.text_content, encoding=\"utf-8\")\n",
    "\n",
    "        print(f\"✅ Converted: {pdf_path.name} → {output_file.name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to convert {pdf_path.name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ecce4-4a14-4127-b84e-ed4a19a2c49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1add513-7f22-4cd6-b1a2-ce3a3b6cb9c5",
   "metadata": {},
   "source": [
    "#### Chunking for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e418a6-a5ae-454a-8065-8a83f9f2904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_book_as_line_doc(md_path: Path) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Input: one markdown file\n",
    "    Output:\n",
    "      {\n",
    "        \"source\": \"<filename.md>\",\n",
    "        \"content\": [<non-empty line>, ...]\n",
    "      }\n",
    "    \"\"\"\n",
    "    text = md_path.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "\n",
    "    lines = [line.strip() for line in text.splitlines()]\n",
    "    lines = [line for line in lines if line]\n",
    "\n",
    "    return {\n",
    "        \"source\": md_path.name,\n",
    "        \"content\": lines,\n",
    "    }\n",
    "\n",
    "def to_gitsource_document(line_doc: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Converts:\n",
    "      {\n",
    "        \"source\": \"...\",\n",
    "        \"content\": [lines]\n",
    "      }\n",
    "    → {\n",
    "        \"filename\": \"...\",\n",
    "        \"content\": [lines]\n",
    "      }\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"filename\": line_doc[\"source\"],\n",
    "        \"content\": line_doc[\"content\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ae3e7bc-5e56-40f7-8a59-52bf243734b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PhysicalModelingInMatlab4.md: 106 chunks\n",
      "✅ Think-C.md: 109 chunks\n",
      "✅ thinkcomplexity2.md: 130 chunks\n",
      "✅ thinkdsp.md: 86 chunks\n",
      "✅ thinkjava2.md: 216 chunks\n",
      "✅ thinkos.md: 62 chunks\n",
      "✅ thinkpython2.md: 214 chunks\n",
      "\n",
      "Total chunks created: 923\n"
     ]
    }
   ],
   "source": [
    "all_chunks = []\n",
    "\n",
    "for md_path in sorted(MARKDOWN_DIR.glob(\"*.md\")):\n",
    "    # Load one book\n",
    "    line_doc = load_book_as_line_doc(md_path)\n",
    "\n",
    "    # Convert to gitsource format\n",
    "    gs_doc = to_gitsource_document(line_doc)\n",
    "\n",
    "    # Item-based chunking of the book (one item = one line)\n",
    "    # Slidding window with 100 items per chunk, step size of 50\n",
    "    chunks = chunk_documents(documents=[to_gitsource_document(line_doc)],\n",
    "                             size=100, step=50)\n",
    "\n",
    "    # Append chunks\n",
    "    all_chunks.extend(chunks)\n",
    "    print(f\"✅ {md_path.name}: {len(chunks)} chunks\")\n",
    "\n",
    "print(f\"\\nTotal chunks created: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17753d1e-1fb9-4bf9-a6b0-7889fd437367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9202c54a-c827-4a63-8fc8-79f249cec2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinkpython2.md 214 chunks\n"
     ]
    }
   ],
   "source": [
    "# Number of chunks in Think Python 2\n",
    "count = sum(\n",
    "    1 for c in all_chunks\n",
    "    if c.get(\"filename\") == \"thinkpython2.md\"\n",
    ")\n",
    "print(\"thinkpython2.md\", count, \"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caec900-3c60-4df1-9ecc-1dca1c5f52f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f0840c4-b2fd-4fc4-bb83-f7a3848baabe",
   "metadata": {},
   "source": [
    "#### Indexing with minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9399ebc-6862-4d21-96a0-21465e58c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_documents_for_search(all_chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Converts gitsource chunks into documents suitable for minsearch.Index.fit()\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "\n",
    "    for i, chunk in enumerate(all_chunks):\n",
    "        # chunk[\"content\"] is a LIST (item-based chunking)\n",
    "        text = \"\\n\".join(chunk[\"content\"])\n",
    "\n",
    "        doc = {\n",
    "            \"id\": f\"{chunk.get('filename', 'doc')}_{i}\",\n",
    "            \"text\": text,\n",
    "            \"source\": chunk.get(\"filename\"),\n",
    "        }\n",
    "\n",
    "        documents.append(doc)\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db8c1968-0804-47e5-9718-c811d69b16cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x24630b2a360>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert each chunk (list of lines) into an indexed block of text\n",
    "documents = prepare_documents_for_search(all_chunks)\n",
    "\n",
    "# Use indexing from the minsearch library\n",
    "index = Index(text_fields=[\"text\"])\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95834f1-b2ad-448c-b5cc-baecda1c9a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8f91e5c-5f03-4973-9ddb-63c1baa0c495",
   "metadata": {},
   "source": [
    "#### Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2de066b5-dd39-4fc8-bc7e-42705dae28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical (rather than semantic) search with the minsearch library\n",
    "results = index.search(\"python function definition\", num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63b43974-a685-4cb2-919f-45703cddbdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thinkpython2.md'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minsearch returns results sorted by descending relevance\n",
    "# The most relevant match for the above user-query is:\n",
    "results[0]['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df82d14c-1d04-4756-a5cd-89f56dbf59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full RAG pipeline\n",
    "import json\n",
    "\n",
    "instructions = \"\"\"\n",
    "You're a course assistant, your task is to answer the QUESTION from the\n",
    "course students using the provided CONTEXT\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(question, search_results):\n",
    "    context = json.dumps(search_results, indent=2)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context\n",
    "    ).strip()\n",
    "    return prompt\n",
    "\n",
    "def search(question):\n",
    "    return index.search(question, num_results=5)\n",
    "\n",
    "def llm(user_prompt, instructions, model='gpt-4o-mini'):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instructions},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        model=model,\n",
    "        input=messages\n",
    "    )\n",
    "\n",
    "    return response.output_text\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt, instructions)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c314cdd-b2bf-4b9d-8fc2-5ed6cd085e78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'openai_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrag\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpython function definition\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mrag\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     44\u001b[39m search_results = search(query)\n\u001b[32m     45\u001b[39m prompt = build_prompt(query, search_results)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m answer = \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mllm\u001b[39m\u001b[34m(user_prompt, instructions, model)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm\u001b[39m(user_prompt, instructions, model=\u001b[33m'\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     31\u001b[39m     messages = [\n\u001b[32m     32\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: instructions},\n\u001b[32m     33\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: user_prompt}\n\u001b[32m     34\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     response = \u001b[43mopenai_client\u001b[49m.responses.create(\n\u001b[32m     37\u001b[39m         model=model,\n\u001b[32m     38\u001b[39m         \u001b[38;5;28minput\u001b[39m=messages\n\u001b[32m     39\u001b[39m     )\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.output_text\n",
      "\u001b[31mNameError\u001b[39m: name 'openai_client' is not defined"
     ]
    }
   ],
   "source": [
    "rag(\"python function definition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe98c08a-71ad-451b-b647-1a4f8b834772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
